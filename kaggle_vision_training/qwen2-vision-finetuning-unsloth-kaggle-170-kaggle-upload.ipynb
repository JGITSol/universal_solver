{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen2-Vision Fine-Tuning on Kaggle with Unsloth and Geo170K\n",
    "\n",
    "This notebook demonstrates how to fine-tune a Qwen2-Vision model using the [Unsloth](https://github.com/unslothai/unsloth) library on Kaggle, following the G-LLaVA procedure and using the [Geo170K dataset](https://huggingface.co/datasets/Luckyjhg/Geo170K) from Hugging Face.\n",
    "\n",
    "**References:**\n",
    "- [G-LLaVA Fine-tuning Procedure](https://github.com/pipilurj/G-LLaVA)\n",
    "- [Unsloth Docs](https://github.com/unslothai/unsloth)\n",
    "- [Geo170K Dataset](https://huggingface.co/datasets/Luckyjhg/Geo170K)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Unsloth, datasets, etc.)\n",
    "!pip install --upgrade --no-cache-dir unsloth loth_zoo datasets huggingface_hub\n",
    "# Optionally: install any other vision/model-specific dependencies if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Hugging Face\n",
    "Store your Hugging Face token in Kaggle Secrets as `HUGGINGFACE_TOKEN`. This is required to download private models/datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Get token from Kaggle Secrets\n",
    "HUGGINGFACE_TOKEN = os.environ.get('HUGGINGFACE_TOKEN', None)\n",
    "if HUGGINGFACE_TOKEN is None:\n",
    "    import kaggle_secrets\n",
    "    HUGGINGFACE_TOKEN = kaggle_secrets.UserSecretsClient().get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "login(token=HUGGINGFACE_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Prepare the Geo170K Dataset\n",
    "We use Hugging Face Datasets to load the Geo170K dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download the dataset\n",
    "dataset = load_dataset('Luckyjhg/Geo170K')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(dataset)\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup for Unsloth & Model Initialization\n",
    "We use Unsloth's FastVisionModel for efficient fine-tuning.\n    \n    **Tip:** Adjust model name and parameters as needed for your experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel\n",
    "\n",
    "# Example: Qwen2-Vision model\n",
    "model_name = 'Qwen/Qwen-VL-Chat'  # Replace with your preferred model\n",
    "model, processor = FastVisionModel.from_pretrained(model_name)\n",
    "\n",
    "# Optionally inspect model\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Fine-Tuning\n",
    "Align the Geo170K dataset with the input format expected by your model.\n    \n    **Tip:** Depending on the dataset structure, you may need to adjust the preprocessing logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    # Example: adapt to your dataset fields\n",
    "    image = example['image']\n",
    "    question = example['question']\n",
    "    answer = example['answer']\n",
    "    # Preprocess image and text as needed\n",
    "    return {\n",
    "        'image': processor(image),\n",
    "        'question': question,\n",
    "        'answer': answer\n",
    "    }\n",
    "\n",
    "processed_dataset = dataset['train'].map(preprocess)\n",
    "\n",
    "# Inspect processed sample\n",
    "print(processed_dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Configuration\n",
    "Set up PEFT (Parameter-Efficient Fine-Tuning) and training arguments.\n    \n    **Tip:** Adjust batch size, learning rate, epochs, and other parameters as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import PEFTTrainer, PEFTConfig\n",
    "\n",
    "peft_config = PEFTConfig(\n",
    "    lora_r=8,\n    # LoRA rank\n",
    "    lora_alpha=16,\n    # LoRA alpha\n",
    "    lora_dropout=0.05,\n    # LoRA dropout\n",
    "    bias='none',\n    # LoRA bias\n",
    "    task_type='VISION_LANGUAGE'\n    # For vision-language models\n",
    ")\n",
    "\n",
    "training_args = {\n",
    "    'per_device_train_batch_size': 8,\n",
    "    'num_train_epochs': 3,\n",
    "    'learning_rate': 2e-4,\n",
    "    'logging_steps': 50,\n",
    "    'save_steps': 200,\n",
    "    'output_dir': './outputs',\n",
    "    'fp16': True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Fine-Tuning\n",
    "Train the model using Unsloth's PEFTTrainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PEFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset,\n",
    "    peft_config=peft_config\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Push Model\n",
    "Save your fine-tuned model and optionally push to Hugging Face Hub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./outputs/final_model')\n",
    "# Optionally: push to Hugging Face\n",
    "# model.push_to_hub('your-hf-username/your-model-name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Tips:**\n",
    "- Adjust model, batch size, epochs, and learning rate for your specific experiment.\n",
    "- Monitor GPU usage and training logs.\n",
    "- Refer to [Unsloth best practices](https://www.reddit.com/r/unsloth/comments/1k12ryj/new_datasets_guide_for_finetuning_best_practices/) and [Kaggle Vision Fine-tuning Example](https://www.kaggle.com/code/danielhanchen/llama-3-2-vision-finetuning-unsloth-kaggle/notebook) for more details.\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook generated on 2025-04-27. For support, see Unsloth and G-LLaVA documentation.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
